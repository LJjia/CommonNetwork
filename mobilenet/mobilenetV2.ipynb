{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20cd5b14-bbcf-49c1-81ff-c1803a807ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817cdba6-08e8-4b78-84f3-5cfffef250b5",
   "metadata": {},
   "source": [
    "# 模型结构图\n",
    "\n",
    "t 为扩张稀疏比例，c 为输出通道数，n 为该层重复的次数，s为步长,输入图片大小224x224x3\n",
    "\n",
    "![pic](mobilenetv2_stru.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b789778-d649-4b71-bb40-6c86ce2630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNReLu(nn.Sequential):\n",
    "    def __init__(self,in_channel,out_channel,kernel_size=3,strides=1,groups=1):\n",
    "        padding=(kernel_size-1)//2\n",
    "        super().__init__(\n",
    "            nn.Conv2d(in_channel,out_channel,kernel_size,strides,padding,groups=groups,bias=False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "        self.out_channel=out_channel\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel,strides,pw_ratio=6):\n",
    "        '''\n",
    "        pw_ratio: 第一个pw的1x1卷积channel数拓展比例\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # strides只能是1 或 2\n",
    "        assert strides in [1, 2]\n",
    "        self.use_shortcut= strides==2 and in_channel==out_channel\n",
    "        hidden_channel=int(round(in_channel*pw_ratio))\n",
    "        layer=[]\n",
    "        if pw_ratio!=1:\n",
    "            # add 1x1 升维\n",
    "            layer.append(ConvBNReLu(in_channel,hidden_channel,kernel_size=1))\n",
    "        layer.extend([\n",
    "            ConvBNReLu(hidden_channel,hidden_channel,strides=strides,groups=hidden_channel),\n",
    "            nn.Conv2d(hidden_channel,out_channel,kernel_size=1,stride=1,padding=0,bias=False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "        ])\n",
    "        self.InvertedResidual=nn.Sequential(*layer)\n",
    "        self.out_channel=out_channel\n",
    "    def forward(self,x):\n",
    "        return x+self.InvertedResidual(x) if self.use_shortcut else self.InvertedResidual(x) \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275d1f98-ee13-4871-905e-ec85ccc85f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "    # 网络默认结构\n",
    "    # 对应参数为 t,c,n,s\n",
    "    net_stru=(\n",
    "    (1, 16, 1, 1),\n",
    "    (6, 24, 2, 2),\n",
    "    (6, 32, 3, 2),\n",
    "    (6, 64, 4, 2),\n",
    "    (6, 96, 3, 1),\n",
    "    (6, 160, 3, 2),\n",
    "    (6, 320, 1, 1),\n",
    "    )\n",
    "    _defaults={\n",
    "        \"first_channel\":32,\n",
    "        \"last_channel\":1280,\n",
    "        \"round_nearest\":8,\n",
    "        \"width_mult\":1.0\n",
    "    }\n",
    "    def __init__(self,num_class=10,net_stru=None,full_conn=True):\n",
    "        '''\n",
    "        width_mult:输入输出的channel扩增比例\n",
    "        num_class: 分类数目\n",
    "        round_nearest:要求每个输入输出都要被round_nearest整除\n",
    "        net_stru: 网络结构的tuple\n",
    "        full_conn: 是否使用最后的全连接层分类层\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.__dict__.update(self._defaults)\n",
    "        # 一些可调参数\n",
    "        if(net_stru):\n",
    "            # 如果外部传入了网络结构,用外部的\n",
    "            self.net_stru=net_stru\n",
    "        if(len(self.net_stru)==0 or len(self.net_stru[0])!=4):\n",
    "            raise ValueError(\"input net struct error %s\",self.net_stru)\n",
    "        self.use_classfy=full_conn\n",
    "        self.num_class=num_class\n",
    "        \n",
    "        # 确保每个输入和输出的通道数都为8的倍数\n",
    "        self.first_channel=MobileNetV2._make_divisible(self.first_channel,self.round_nearest)\n",
    "        # 也就是说输出至少是1280,可以被调大\n",
    "        self.last_channel=MobileNetV2._make_divisible(self.last_channel*max(self.width_mult,1.0),self.round_nearest)\n",
    "        features=[ConvBNReLu(3,self.first_channel,strides=2)]\n",
    "        # 记录第一个输入通道数\n",
    "        in_channel=self.first_channel\n",
    "        for t,c,n,s in self.net_stru:\n",
    "            out_channel=MobileNetV2._make_divisible(c*self.width_mult,self.round_nearest)\n",
    "            for cnt in range(n):\n",
    "                # 几个连续的倒残差块,仅第一个卷积的跨距大小会有不同\n",
    "                if cnt==0:\n",
    "                    strides=s\n",
    "                else:\n",
    "                    strides=1\n",
    "                features.append(InvertedResidual(in_channel,out_channel,strides,pw_ratio=t))\n",
    "                in_channel=out_channel\n",
    "        # 加上最后的转变成conv2d 1x1的卷积\n",
    "        features.append(ConvBNReLu(in_channel,self.last_channel,kernel_size=1))\n",
    "        self.bone=nn.Sequential(*features)\n",
    "        \n",
    "        if(self.use_classfy):\n",
    "            self.classify=nn.Sequential(\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(self.last_channel,self.num_class),\n",
    "            )\n",
    "        self.weight_init()\n",
    "        \n",
    "    def weight_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # 一种正态分布\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "                \n",
    "    def forward(self,x):\n",
    "        out=self.bone(x)\n",
    "        if(self.use_classfy):\n",
    "            # 对2,3两个维度求平均,也就是把batchx1280x7x7的向量\n",
    "            # 求解为batchx1280的维度\n",
    "            out=out.mean([2,3])\n",
    "            out=self.classify(out)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_divisible(v, divisor, min_value=None):\n",
    "        '''\n",
    "        全是整数运算,保证返回的new_v可以被divisor整除\n",
    "        :param v:输入channel数量,例如32\n",
    "        :param divisor:被整除的数字,一般为8,硬件要求对齐\n",
    "        :param min_value:\n",
    "        :return:\n",
    "        '''\n",
    "        if min_value is None:\n",
    "            min_value = divisor\n",
    "        # int(v + divisor / 2) // divisor * divisor 这句是求v被8整除的floor\n",
    "        new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "        if new_v < 0.9 * v:\n",
    "            new_v += divisor\n",
    "        return new_v  \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b7a9927-a306-42ea-bd6c-f85d3b2c2a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "net=MobileNetV2()\n",
    "net.to(device)\n",
    "rand_data=torch.randn(4,3,224,224).to(device)\n",
    "out=net(rand_data)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca23e53b-9582-45ff-b26a-741a48449dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意torch里是宽高顺序,和PIL不同\n",
    "img_size=(224,224)\n",
    "# mean和std均值需要按照数据集来修改\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "batch=64\n",
    "lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e431f28-70d0-4fbd-baa1-9520f18a3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare dataset and preprocessing\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.RandomCrop(img_size, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # 至少要加上下面这句ToTensor\n",
    "    transforms.ToTensor(),\n",
    "    # ciaf10固有均值标准差\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    # 至少要加上下面这句ToTensor\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac197bd4-26ae-4cdc-8feb-72ed99bd7b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 23556\n",
      "val data 2623\n",
      "train label {'cane': 0, 'cavallo': 1, 'elefante': 2, 'farfalla': 3, 'gallina': 4, 'gatto': 5, 'mucca': 6, 'pecora': 7, 'ragno': 8, 'scoiattolo': 9}\n",
      "val label {'cane': 0, 'cavallo': 1, 'elefante': 2, 'farfalla': 3, 'gallina': 4, 'gatto': 5, 'mucca': 6, 'pecora': 7, 'ragno': 8, 'scoiattolo': 9}\n"
     ]
    }
   ],
   "source": [
    "# minist数据集\n",
    "# 正常来说,train_set这个类是需要自己定义的,但是在官方数据集中已经给定义好了\n",
    "data_dir=\"D:/data/image/\"\n",
    "if not os.path.exists(data_dir):\n",
    "    # 尝试mac的文件夹\n",
    "    data_dir=\"~/data\"\n",
    "    if not os.path.exists(data_dir):\n",
    "            raise FileExistsError(\"data source not exist!\")\n",
    "train_set=datasets.ImageFolder(root=data_dir+'animals10/train',\n",
    "                        transform=transform_train)\n",
    "\n",
    "val_set=datasets.ImageFolder(root=data_dir+'animals10/val',\n",
    "                        transform=transform_val)\n",
    "train_set_len=len(train_set)\n",
    "val_set_len=len(val_set)\n",
    "print('train data',train_set_len)\n",
    "print('val data',val_set_len)\n",
    "print('train label',train_set.class_to_idx)\n",
    "print('val label',val_set.class_to_idx)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch,\n",
    "                                         shuffle=True, num_workers=6)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch,\n",
    "                                         shuffle=False, num_workers=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "370f509f-af13-48f3-915b-c6c8626ce317",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcLoss(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super().__init__()\n",
    "        self.criterion=nn.CrossEntropyLoss()\n",
    "    def forward(self,y_true,y_pred):\n",
    "        return self.criterion(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c97bf317-aa47-4ba2-9ab0-bb4ffc463a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel(object):\n",
    "    _defaults={\n",
    "        \"eopch\":2,\n",
    "    }\n",
    "    def __init__(self,net,loss,train_dataloder,optimizer,**kwargs):\n",
    "        '''\n",
    "        还支持传入字典参数\n",
    "        '''\n",
    "        self.__dict__.update(self._defaults)\n",
    "        self.net=net\n",
    "        self.loss=loss\n",
    "        self.dataloder=train_dataloder\n",
    "        self.optimizer=optimizer\n",
    "        for name, value in kwargs.items():\n",
    "            setattr(self, name, value)\n",
    "        self.device='cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "    def __call__(self,train_total_len,batch_size):\n",
    "        self.net.train()\n",
    "        # 需要注意这里写的是train_set的长度,如果写错成train_loader,返回的是数据集一共有多少个batch\n",
    "        with tqdm(total=train_total_len,desc=f'Train:') as pbar:\n",
    "            for idx,data in enumerate(self.dataloder):\n",
    "                data,label=data\n",
    "                data,label=data.to(self.device),label.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                # forward\n",
    "                outputs=self.net(data)\n",
    "                loss=self.loss(outputs,label)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                # 更新进度条\n",
    "                pbar.update(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfcda5c5-c3fd-4aa9-ad88-993d3babe8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(object):\n",
    "    _defaults={\n",
    "    \"eopch\":1,\n",
    "    }\n",
    "    def __init__(self,net,loss,val_dataloder,**kwargs):\n",
    "        '''\n",
    "        还支持传入字典参数\n",
    "        '''\n",
    "        self.__dict__.update(self._defaults)\n",
    "        self.net=net\n",
    "        self.loss=loss\n",
    "        self.dataloder=val_dataloder\n",
    "        for name, value in kwargs.items():\n",
    "            setattr(self, name, value)\n",
    "        self.device='cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "    def __call__(self,total_num,batch_size):\n",
    "        # eval 模式下,dropout失效,bn层参数采用之前训练的,不更新\n",
    "        self.net.eval()\n",
    "        val_loss=0\n",
    "        correct=0\n",
    "        with tqdm(total=total_num,desc=f'Validation:') as pbar:\n",
    "            # 不计算损失,这样速度更快\n",
    "            with torch.no_grad():\n",
    "                for idx,data in enumerate(self.dataloder):\n",
    "                    x,y=data\n",
    "                    x,y=x.to(self.device),y.to(self.device)\n",
    "                    y_pre=self.net(x)\n",
    "                    val_loss+=self.loss(y_pre,y).item()\n",
    "                    # max 第一个返回的是元素值,第二个为索引值\n",
    "                    # 求第一个维度的max,因此结果返回的是batch维度的max\n",
    "                    # 返回是一个第一个元素为值,第二个元素为idx的tuple\n",
    "                    pred=torch.max(y_pre,dim=1)[1]\n",
    "\n",
    "                    # pred维度为batch,每个元素为索引\n",
    "                    correct+=pred.eq(y).sum().item()\n",
    "                    # 更新进度条\n",
    "                    pbar.update(batch_size)\n",
    "            # 格式化打印直接有% 带f%这种{:.2f%}是错的格式,format这种有点坑\n",
    "            print(\"test loss {},accuracy {:.2%}\".format(val_loss,correct/total_num))\n",
    "        # 返回损失和准确率\n",
    "        return (val_loss,correct/total_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3d00dd0-be16-4e77-b341-c54b559beeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD(net.parameters(),lr=lr,momentum=0.9)\n",
    "loss=CalcLoss().to(device)\n",
    "train=TrainModel(net,loss,train_loader,optimizer)\n",
    "test=TestModel(net,loss,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10781b7b-dd75-4b70-a1c7-19eaf21f3fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [01:15, 311.42it/s]                                                                                                  \n",
      "Validation:: 2624it [00:10, 260.48it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 73.228730738163,accuracy 40.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [01:10, 335.69it/s]                                                                                                  \n",
      "Validation:: 2624it [00:10, 261.02it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 58.42719841003418,accuracy 51.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [01:10, 335.93it/s]                                                                                                  \n",
      "Validation:: 2624it [00:10, 255.17it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 49.77328488230705,accuracy 58.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [01:10, 334.95it/s]                                                                                                  \n",
      "Validation:: 2624it [00:10, 259.54it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 48.3777861893177,accuracy 59.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [01:10, 336.04it/s]                                                                                                  \n",
      "Validation:: 2624it [00:10, 258.34it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 53.80790504813194,accuracy 57.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [01:10, 335.85it/s]                                                                                                  \n",
      "Validation:: 2624it [00:10, 258.00it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 41.11389338970184,accuracy 66.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [01:10, 335.81it/s]                                                                                                  \n",
      "Validation:: 2624it [00:10, 260.52it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 39.15046951174736,accuracy 67.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [01:10, 334.60it/s]                                                                                                  \n",
      "Validation:: 2624it [00:10, 258.11it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 39.20372584462166,accuracy 68.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [01:10, 335.11it/s]                                                                                                  \n",
      "Validation:: 2624it [00:10, 257.66it/s]                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 34.93609642982483,accuracy 72.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train::  41%|█████████████████████████████████▊                                                | 9728/23556 [00:32<00:37, 369.78it/s]"
     ]
    }
   ],
   "source": [
    "total_epoch=10\n",
    "for i in range(total_epoch):\n",
    "    train(train_set_len,batch)\n",
    "    test(val_set_len,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33430af6-014c-4998-a591-c765fc4241f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),\"mobilenetV2_loss100_accuracy78.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
