{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e84765d-5412-446e-abbf-395243f6a2bf",
   "metadata": {},
   "source": [
    "# ShuffleNetV1\n",
    "\n",
    "首先需要了解分组卷积的概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3ad16-e550-46a4-92ec-472bab7cfdca",
   "metadata": {},
   "source": [
    "## 基本单元如下\n",
    "\n",
    "![unit](shuffnetv1_unit.png)\n",
    "\n",
    "## 结构如下\n",
    "\n",
    "repeat为重复次数,g列对应的输入,表示group取对应值的时候,该层输出可能会有变化.而对于瓶颈层，将通道设为每个ShuffleNet单元输出通道的1/4\n",
    "\n",
    "![unit](shuffnetv1_stru.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d0e1335-ef23-41be-bb36-c8c93a5fce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98fdecef-8b61-49f3-8dcc-0e6a3d309414",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, groups):\n",
    "        super().__init__()\n",
    "        # 瓶颈层输出为每个单元输出的1/4\n",
    "        mid_channles = int(out_channels/4)\n",
    "        # 作者提到不在stage2的第一个pointwise层使用组卷积,因为输入channel数量太少,只有24\n",
    "        # 所以第一个stage特殊处理\n",
    "        if in_channels <=24:\n",
    "            self.groups = 1\n",
    "        else:\n",
    "            self.groups = groups\n",
    "        self.stride = stride\n",
    "        # 分组1x1卷积,特征图深度变为本单元输出的1/4\n",
    "        self.conv1 = nn.Sequential(\n",
    "            # 第一个stage的第一个1x1可能会不用组卷积,所以特殊处理下\n",
    "            nn.Conv2d(in_channels, mid_channles, 1, groups=self.groups, bias=False),\n",
    "            nn.BatchNorm2d(mid_channles),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # 跨距为2时,缩小特征图wh,不改变深度,后接bn无relu\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(mid_channles, mid_channles, 3, stride=stride, padding=1, groups=mid_channles, bias=False),\n",
    "            nn.BatchNorm2d(mid_channles)\n",
    "        )\n",
    "        # 分组1x1卷积,不改变尺寸,但是改变深度为输出深度,后接bn无relu\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(mid_channles, out_channels, 1, groups=groups, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        if(self.stride==2):\n",
    "            # 特征图尺寸减为一半,和跨距为2的效果相同\n",
    "            self.shortcut = nn.Sequential(nn.AvgPool2d(3, stride=2, padding=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        # shuffle单元只对第一个1x1分组卷积之后进行shuffle,作者说第二个1x1卷积之后再做shuffle效果一般\n",
    "        out = Bottleneck.shuffle(out, self.groups)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        if self.stride == 2:\n",
    "            # 堆叠后,输出深度为out_channel+in_channel,外层需注意\n",
    "            res = self.shortcut(x)\n",
    "            out = F.relu(torch.cat([out, res], 1))\n",
    "        else:\n",
    "            # 都是对最后的输出加上relu\n",
    "            out = F.relu(out+x)\n",
    "        return out\n",
    "    @staticmethod\n",
    "    def shuffle(x, groups):\n",
    "        N, C, H, W = x.size()\n",
    "        out = x.view(N, groups, C // groups, H, W).permute(0, 2, 1, 3, 4).contiguous().view(N, C, H, W)\n",
    "        return out\n",
    "    \n",
    "class ShuffleNet(nn.Module):\n",
    "    channel_num=(\n",
    "        # 有关各种group对应每层的输出参数\n",
    "        # group的取值为1,2,3,4,8\n",
    "        (144,288,576),\n",
    "        (200,400,800),\n",
    "        (240,480,960),\n",
    "        (272,544,1088),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (384,768,1536),\n",
    "    )\n",
    "    groups_area=(1,2,3,4,8)\n",
    "    def __init__(self, groups, first_channel=3,class_num=10):\n",
    "        super().__init__()\n",
    "        self.class_num=class_num\n",
    "        if not groups in self.groups_area:\n",
    "            raise ValueError(\"groups value %s error\"%groups)\n",
    "        self.groups=groups\n",
    "        self.channel_stru=self.channel_num[self.groups]\n",
    "        # in 224x224x3\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(first_channel, 24, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # in 56x56xx24\n",
    "        self.stage2 = self.make_layers(24, self.channel_stru[0], repeat_times=4, strides=2, groups=groups)\n",
    "        self.stage3 = self.make_layers(self.channel_stru[0], self.channel_stru[1], repeat_times=8, strides=2, groups=groups)\n",
    "        self.stage4 = self.make_layers(self.channel_stru[1], self.channel_stru[2], repeat_times=4, strides=2, groups=groups)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(self.channel_stru[2],self.class_num)\n",
    "    def make_layers(self, input_channels, output_channels, repeat_times, strides, groups):\n",
    "        layers = []\n",
    "        if strides!=2:\n",
    "            raise ValueError(\"first head conv strides must 2\",strides)\n",
    "        # 第一层跨距为2,肯定会进行堆叠,所以输出层输写成 实际输出-输入层数\n",
    "        layers.append(Bottleneck(input_channels, output_channels - input_channels, strides, groups))\n",
    "        input_channels = output_channels\n",
    "        for i in range(repeat_times - 1):\n",
    "            Bottleneck(input_channels, output_channels, 1, groups)\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.avgpool(x)\n",
    "        # 这之后还是ncwh四维的,不过是(n,1024,1,1)这种\n",
    "        # flatten(1),从第1个维度开始到一直展平到最后一个维度\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87dc559-67b9-4781-8b49-03b15271c268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=ShuffleNet(groups=2)\n",
    "data=torch.randn(4,3,224,224)\n",
    "out=net(data)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c20bbf74-a869-47ea-a7b4-bf9bbd8b0cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShuffleNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (stage2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(24, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(54, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=54, bias=False)\n",
       "        (1): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): Conv2d(54, 216, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)\n",
       "        (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)\n",
       "        (1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(60, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=60, bias=False)\n",
       "        (1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): Conv2d(60, 240, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)\n",
       "        (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=120, bias=False)\n",
       "        (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=960, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd66a28f-dd09-432b-93a0-0491c1625891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意torch里是宽高顺序,和PIL不同\n",
    "img_size=(224,224)\n",
    "# mean和std均值需要按照数据集来修改\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "batch=64\n",
    "lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38fc90dd-e84c-4e3c-b22d-fd5b85885fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare dataset and preprocessing\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.RandomCrop(img_size, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # 至少要加上下面这句ToTensor\n",
    "    transforms.ToTensor(),\n",
    "    # ciaf10固有均值标准差\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    # 至少要加上下面这句ToTensor\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe710c2f-6aba-4835-9ac4-71e1f39b8a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 23556\n",
      "val data 2623\n",
      "train label {'cane': 0, 'cavallo': 1, 'elefante': 2, 'farfalla': 3, 'gallina': 4, 'gatto': 5, 'mucca': 6, 'pecora': 7, 'ragno': 8, 'scoiattolo': 9}\n",
      "val label {'cane': 0, 'cavallo': 1, 'elefante': 2, 'farfalla': 3, 'gallina': 4, 'gatto': 5, 'mucca': 6, 'pecora': 7, 'ragno': 8, 'scoiattolo': 9}\n"
     ]
    }
   ],
   "source": [
    "# animals10数据集\n",
    "# 正常来说,train_set这个类是需要自己定义的,但是在官方数据集中已经给定义好了\n",
    "data_dir=\"D:/data/image/\"\n",
    "if not os.path.exists(data_dir):\n",
    "    # 尝试mac的文件夹\n",
    "    data_dir=\"~/data\"\n",
    "    if not os.path.exists(data_dir):\n",
    "            raise FileExistsError(\"data source not exist!\")\n",
    "train_set=datasets.ImageFolder(root=data_dir+'animals10/train',\n",
    "                        transform=transform_train)\n",
    "\n",
    "val_set=datasets.ImageFolder(root=data_dir+'animals10/val',\n",
    "                        transform=transform_val)\n",
    "train_set_len=len(train_set)\n",
    "val_set_len=len(val_set)\n",
    "print('train data',train_set_len)\n",
    "print('val data',val_set_len)\n",
    "print('train label',train_set.class_to_idx)\n",
    "print('val label',val_set.class_to_idx)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch,\n",
    "                                         shuffle=True, num_workers=6)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch,\n",
    "                                         shuffle=False, num_workers=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02d87e46-4630-432f-9e5d-f17eafeae6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcLoss(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super().__init__()\n",
    "        self.criterion=nn.CrossEntropyLoss()\n",
    "    def forward(self,y_true,y_pred):\n",
    "        return self.criterion(y_true,y_pred)\n",
    "    \n",
    "class TrainModel(object):\n",
    "    _defaults={\n",
    "        \"eopch\":2,\n",
    "    }\n",
    "    def __init__(self,net,loss,train_dataloder,optimizer,**kwargs):\n",
    "        '''\n",
    "        还支持传入字典参数\n",
    "        '''\n",
    "        self.__dict__.update(self._defaults)\n",
    "        self.net=net\n",
    "        self.loss=loss\n",
    "        self.dataloder=train_dataloder\n",
    "        self.optimizer=optimizer\n",
    "        for name, value in kwargs.items():\n",
    "            setattr(self, name, value)\n",
    "        self.device='cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "    def __call__(self,train_total_len,batch_size):\n",
    "        self.net.train()\n",
    "        # 需要注意这里写的是train_set的长度,如果写错成train_loader,返回的是数据集一共有多少个batch\n",
    "        with tqdm(total=train_total_len,desc=f'Train:') as pbar:\n",
    "            for idx,data in enumerate(self.dataloder):\n",
    "                data,label=data\n",
    "                data,label=data.to(self.device),label.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                # forward\n",
    "                outputs=self.net(data)\n",
    "                loss=self.loss(outputs,label)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                # 更新进度条\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "class TestModel(object):\n",
    "    _defaults={\n",
    "    \"eopch\":1,\n",
    "    }\n",
    "    def __init__(self,net,loss,val_dataloder,**kwargs):\n",
    "        '''\n",
    "        还支持传入字典参数\n",
    "        '''\n",
    "        self.__dict__.update(self._defaults)\n",
    "        self.net=net\n",
    "        self.loss=loss\n",
    "        self.dataloder=val_dataloder\n",
    "        for name, value in kwargs.items():\n",
    "            setattr(self, name, value)\n",
    "        self.device='cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "    def __call__(self,total_num,batch_size):\n",
    "        # eval 模式下,dropout失效,bn层参数采用之前训练的,不更新\n",
    "        self.net.eval()\n",
    "        val_loss=0\n",
    "        correct=0\n",
    "        with tqdm(total=total_num,desc=f'Validation:') as pbar:\n",
    "            # 不计算损失,这样速度更快\n",
    "            with torch.no_grad():\n",
    "                for idx,data in enumerate(self.dataloder):\n",
    "                    x,y=data\n",
    "                    x,y=x.to(self.device),y.to(self.device)\n",
    "                    y_pre=self.net(x)\n",
    "                    val_loss+=self.loss(y_pre,y).item()\n",
    "                    # max 第一个返回的是元素值,第二个为索引值\n",
    "                    # 求第一个维度的max,因此结果返回的是batch维度的max\n",
    "                    # 返回是一个第一个元素为值,第二个元素为idx的tuple\n",
    "                    pred=torch.max(y_pre,dim=1)[1]\n",
    "\n",
    "                    # pred维度为batch,每个元素为索引\n",
    "                    correct+=pred.eq(y).sum().item()\n",
    "                    # 更新进度条\n",
    "                    pbar.update(batch_size)\n",
    "            # 格式化打印直接有% 带f%这种{:.2f%}是错的格式,format这种有点坑\n",
    "            print(\"test loss {},accuracy {:.2%}\".format(val_loss,correct/total_num))\n",
    "        # 返回损失和准确率\n",
    "        return (val_loss,correct/total_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c36646e8-b034-4eee-880e-962a1d106f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD(net.parameters(),lr=lr,momentum=0.9)\n",
    "loss=CalcLoss().to(device)\n",
    "train=TrainModel(net,loss,train_loader,optimizer)\n",
    "test=TestModel(net,loss,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e95006c0-8b95-48cf-8174-76cbcaf39b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [00:26, 884.62it/s]                                                                                                \n",
      "Validation:: 2624it [00:09, 285.04it/s]                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 37.586592614650726,accuracy 70.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [00:26, 883.54it/s]                                                                                                \n",
      "Validation:: 2624it [00:09, 284.59it/s]                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 36.34435893595219,accuracy 70.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [00:26, 879.93it/s]                                                                                                \n",
      "Validation:: 2624it [00:09, 283.61it/s]                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 34.46480464935303,accuracy 71.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [00:26, 878.31it/s]                                                                                                \n",
      "Validation:: 2624it [00:09, 272.24it/s]                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 35.90738967806101,accuracy 71.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [00:27, 862.26it/s]                                                                                                \n",
      "Validation:: 2624it [00:09, 283.00it/s]                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 36.119284614920616,accuracy 71.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [00:27, 861.39it/s]                                                                                                \n",
      "Validation:: 2624it [00:09, 283.88it/s]                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 34.268888011574745,accuracy 72.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [00:27, 864.76it/s]                                                                                                \n",
      "Validation:: 2624it [00:09, 283.28it/s]                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 32.148918479681015,accuracy 75.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [00:27, 859.65it/s]                                                                                                \n",
      "Validation:: 2624it [00:09, 281.91it/s]                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 31.773900374770164,accuracy 75.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [00:27, 856.01it/s]                                                                                                \n",
      "Validation:: 2624it [00:09, 285.27it/s]                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 32.455738842487335,accuracy 74.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:: 23616it [00:27, 867.82it/s]                                                                                                \n",
      "Validation:: 2624it [00:09, 282.70it/s]                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 31.127081111073494,accuracy 75.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_epoch=10\n",
    "for i in range(total_epoch):\n",
    "    train(train_set_len,batch)\n",
    "    test(val_set_len,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05778f5e-c5e1-4b8f-b9b1-0e8a7ddd079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),\"shufflenetv1_loss31_accuracy75.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62106282-2bf1-4399-975c-0686724985ec",
   "metadata": {},
   "source": [
    "## 大小\n",
    "\n",
    "这个模型才400KB,可以说是非常小了!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff70675e-ef69-4b46-aed6-c9eda885818c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
