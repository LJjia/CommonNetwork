{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e84765d-5412-446e-abbf-395243f6a2bf",
   "metadata": {},
   "source": [
    "# ShuffleNetV1\n",
    "\n",
    "首先需要了解分组卷积的概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3ad16-e550-46a4-92ec-472bab7cfdca",
   "metadata": {},
   "source": [
    "## 基本单元如下\n",
    "\n",
    "![unit](shuffnetv1_unit.png)\n",
    "\n",
    "## 结构如下\n",
    "\n",
    "repeat为重复次数,g列对应的输入,表示group取对应值的时候,该层输出可能会有变化.而对于瓶颈层，将通道设为每个ShuffleNet单元输出通道的1/4\n",
    "\n",
    "![unit](shuffnetv1_stru.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d0e1335-ef23-41be-bb36-c8c93a5fce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98fdecef-8b61-49f3-8dcc-0e6a3d309414",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, groups):\n",
    "        super().__init__()\n",
    "        # 瓶颈层输出为每个单元输出的1/4\n",
    "        mid_channles = int(out_channels/4)\n",
    "        # 作者提到不在stage2的第一个pointwise层使用组卷积,因为输入channel数量太少,只有24\n",
    "        # 所以第一个stage特殊处理\n",
    "        if in_channels <=24:\n",
    "            self.groups = 1\n",
    "        else:\n",
    "            self.groups = groups\n",
    "        self.stride = stride\n",
    "        # 分组1x1卷积,特征图深度变为本单元输出的1/4\n",
    "        self.conv1 = nn.Sequential(\n",
    "            # 第一个stage的第一个1x1可能会不用组卷积,所以特殊处理下\n",
    "            nn.Conv2d(in_channels, mid_channles, 1, groups=self.groups, bias=False),\n",
    "            nn.BatchNorm2d(mid_channles),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # 跨距为2时,缩小特征图wh,不改变深度,后接bn无relu\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(mid_channles, mid_channles, 3, stride=stride, padding=1, groups=mid_channles, bias=False),\n",
    "            nn.BatchNorm2d(mid_channles)\n",
    "        )\n",
    "        # 分组1x1卷积,不改变尺寸,但是改变深度为输出深度,后接bn无relu\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(mid_channles, out_channels, 1, groups=groups, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        if(self.stride==2):\n",
    "            # 特征图尺寸减为一半,和跨距为2的效果相同\n",
    "            self.shortcut = nn.Sequential(nn.AvgPool2d(3, stride=2, padding=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        # shuffle单元只对第一个1x1分组卷积之后进行shuffle,作者说第二个1x1卷积之后再做shuffle效果一般\n",
    "        out = Bottleneck.shuffle(out, self.groups)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        if self.stride == 2:\n",
    "            # 堆叠后,输出深度为out_channel+in_channel,外层需注意\n",
    "            res = self.shortcut(x)\n",
    "            out = F.relu(torch.cat([out, res], 1))\n",
    "        else:\n",
    "            # 都是对最后的输出加上relu\n",
    "            out = F.relu(out+x)\n",
    "        return out\n",
    "    @staticmethod\n",
    "    def shuffle(x, groups):\n",
    "        N, C, H, W = x.size()\n",
    "        out = x.view(N, groups, C // groups, H, W).permute(0, 2, 1, 3, 4).contiguous().view(N, C, H, W)\n",
    "        return out\n",
    "    \n",
    "class ShuffleNet(nn.Module):\n",
    "    channel_num=(\n",
    "        # 有关各种group对应每层的输出参数\n",
    "        # group的取值为1,2,3,4,8\n",
    "        (144,288,576),\n",
    "        (200,400,800),\n",
    "        (240,480,960),\n",
    "        (272,544,1088),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (384,768,1536),\n",
    "    )\n",
    "    groups_area=(1,2,3,4,8)\n",
    "    def __init__(self, groups, first_channel=3,class_num=10):\n",
    "        super().__init__()\n",
    "        self.class_num=class_num\n",
    "        if not groups in self.groups_area:\n",
    "            raise ValueError(\"groups value %s error\"%groups)\n",
    "        self.groups=groups\n",
    "        self.channel_stru=self.channel_num[self.groups]\n",
    "        # in 224x224x3\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(first_channel, 24, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # in 56x56xx24\n",
    "        self.stage2 = self.make_layers(24, self.channel_stru[0], repeat_times=4, strides=2, groups=groups)\n",
    "        self.stage3 = self.make_layers(self.channel_stru[0], self.channel_stru[1], repeat_times=8, strides=2, groups=groups)\n",
    "        self.stage4 = self.make_layers(self.channel_stru[1], self.channel_stru[2], repeat_times=4, strides=2, groups=groups)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(self.channel_stru[2],self.class_num)\n",
    "    def make_layers(self, input_channels, output_channels, repeat_times, strides, groups):\n",
    "        layers = []\n",
    "        if strides!=2:\n",
    "            raise ValueError(\"first head conv strides must 2\",strides)\n",
    "        # 第一层跨距为2,肯定会进行堆叠,所以输出层输写成 实际输出-输入层数\n",
    "        layers.append(Bottleneck(input_channels, output_channels - input_channels, strides, groups))\n",
    "        input_channels = output_channels\n",
    "        for i in range(repeat_times - 1):\n",
    "            Bottleneck(input_channels, output_channels, 1, groups)\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.avgpool(x)\n",
    "        # 这之后还是ncwh四维的,不过是(n,1024,1,1)这种\n",
    "        # flatten(1),从第1个维度开始到一直展平到最后一个维度\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c87dc559-67b9-4781-8b49-03b15271c268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=ShuffleNet(groups=2)\n",
    "data=torch.randn(4,3,224,224)\n",
    "out=net(data)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20bbf74-a869-47ea-a7b4-bf9bbd8b0cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd66a28f-dd09-432b-93a0-0491c1625891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
