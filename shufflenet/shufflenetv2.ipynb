{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60cc9da3-2d04-4ddc-b0a2-03dcf1cea9ce",
   "metadata": {},
   "source": [
    "# shufflenetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cd636c-2f95-48e9-8fae-d5ec0b23d6f7",
   "metadata": {},
   "source": [
    "# 模型结构\n",
    "\n",
    "## 基本模块\n",
    "\n",
    "![pic](shufflenetv2_unit.jpg)\n",
    "\n",
    "## 模型骨架\n",
    "\n",
    "![pic](shufflenetv2_stru.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df59991c-a5f8-4e9f-9101-5c4511aaa80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3673df4a-02f1-4351-b25e-a26e06d85306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本单元    \n",
    "class ShuffleUnit(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel,strides,grps=2):\n",
    "        super().__init__()\n",
    "        # strides 必须为1或2\n",
    "        if not strides in (1,2):\n",
    "            raise ValueError(\"input strides %s\",strides)\n",
    "        \n",
    "        self.strides=strides\n",
    "        self.groups=grps\n",
    "\n",
    "        # 涉及这种非翻倍维度变换的卷积,只在Conv1-stage2的时候有发生\n",
    "        # 而且只是主副branch都是变换到输出的一半,请注意,变换一定是1x1卷积发生变换,3x3是DW卷积,尺度不可变换\n",
    "        # pytorch官方就是这么实现的\n",
    "        mid_channel=out_channel//2\n",
    "        if(strides==1):\n",
    "            self.short=nn.Sequential()\n",
    "        else:\n",
    "            self.short=nn.Sequential(\n",
    "                nn.Conv2d(in_channel, in_channel, 3, stride=self.strides, padding=1, groups=in_channel, bias=False),\n",
    "                nn.BatchNorm2d(in_channel),\n",
    "                nn.Conv2d(in_channel, mid_channel, 1, bias=False),\n",
    "                nn.BatchNorm2d(mid_channel),\n",
    "                nn.ReLU6(inplace=True),\n",
    "            )\n",
    "        # 注意,3x3的DW卷积无法变换维度,只有1x1卷积可变换维度\n",
    "        self.branch=nn.Sequential(\n",
    "            nn.Conv2d(in_channel,mid_channel,1,bias=False),\n",
    "            nn.BatchNorm2d(mid_channel),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(mid_channel,mid_channel,3,stride=self.strides,padding=1,groups=mid_channel,bias=False),\n",
    "            nn.BatchNorm2d(mid_channel),\n",
    "            nn.Conv2d(mid_channel,mid_channel,1,bias=False),\n",
    "            nn.BatchNorm2d(mid_channel),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        if self.strides==1:\n",
    "            short,res=ShuffleUnit.channel_split(x)\n",
    "        else :\n",
    "            # strides=2,输入都为short和残差都是x\n",
    "            short=x\n",
    "            res=x\n",
    "        out=torch.cat((self.short(short),self.branch(res)),dim=1)\n",
    "        '''\n",
    "        默认2组混洗\n",
    "        '''\n",
    "        return ShuffleUnit.shuffle(out,self.groups)\n",
    "    \n",
    "    @staticmethod\n",
    "    def channel_split(x,grps=2):\n",
    "        # ncwh 按照c分成grps组,默认对半分\n",
    "        return x.chunk(grps,dim=1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def shuffle(x, groups=2):\n",
    "        # 一半默认groups=2,当然也可以等于3或者其他值,但不易过大\n",
    "        # 对c按照groups混洗\n",
    "        N, C, H, W = x.size()\n",
    "        out = x.view(N, groups, C // groups, H, W).permute(0, 2, 1, 3, 4).contiguous().view(N, C, H, W)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43cc226-90d3-4b4f-8241-df57b4bdf2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主结构\n",
    "class ShuffleNetV2(nn.Module):\n",
    "    '''\n",
    "    图片默认输入大小224x224\n",
    "    '''\n",
    "    output_channel=(\n",
    "        # 有关各种group对应每层的输出参数\n",
    "        # group的取值为1,2,3,4,8\n",
    "        (24,48,96,192,1024),\n",
    "        (24,116,232,464,1024),\n",
    "        (24,176,352,704,1024),\n",
    "        (24,244,488,976,2048),\n",
    "    )\n",
    "    repeat_times=(4,8,4)\n",
    "    scale=(0.5,1,1,5,2)\n",
    "    def __init__(self, scale=1,in_channel=3, class_num=10,pre_train=False):\n",
    "        super().__init__()\n",
    "        assert scale in self.scale\n",
    "        # 对应索引变为0,1,2,3\n",
    "        self.use_cfg=int(scale*2)-1\n",
    "        print(\"==use ShuffleNetV2 mode %s==\"%scale)\n",
    "        # 第一层正常卷积,跨距2\n",
    "        self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, self.output_channel[self.use_cfg][0], kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(24),\n",
    "                nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # 56x56x24\n",
    "        self.stage2 = self.make_layers(self.output_channel[self.use_cfg][0], self.output_channel[self.use_cfg][1], self.repeat_times[0], 2)\n",
    "        # 28x28\n",
    "        self.stage3 = self.make_layers(self.output_channel[self.use_cfg][1], self.output_channel[self.use_cfg][2], self.repeat_times[1], 2)\n",
    "        # 14x14\n",
    "        self.stage4 = self.make_layers(self.output_channel[self.use_cfg][2], self.output_channel[self.use_cfg][3], self.repeat_times[2], 2)\n",
    "        # 对应输出会有7x7x1024 和 7x7x2048\n",
    "        self.conv5 = nn.Sequential(\n",
    "                nn.Conv2d(self.output_channel[self.use_cfg][3], self.output_channel[self.use_cfg][4], 1, bias=False),\n",
    "                nn.BatchNorm2d(self.output_channel[self.use_cfg][4]),\n",
    "                nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # 自适应池化后变为 batchx1x1x1024\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(self.output_channel[self.use_cfg][4], class_num)\n",
    "        if not pre_train:\n",
    "            self.init_params()\n",
    "        \n",
    "    def make_layers(self, in_channels, output_channel, layers_num, stride):\n",
    "        layers = []\n",
    "        # 仅第一层跨距会为2\n",
    "        layers.append(ShuffleUnit(in_channels, output_channel, stride))\n",
    "        in_channels = output_channel\n",
    "        for i in range(layers_num - 1):\n",
    "            ShuffleUnit(in_channels, output_channel, 1)\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.stage2(out)\n",
    "        out = self.stage3(out)\n",
    "        out = self.stage4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.avgpool(out)\n",
    "        # batch x1x1x1024展平\n",
    "        out = out.flatten(1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    # 何凯明的方法初始化权重\n",
    "    def init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # 如果卷积操作后面没有使用激活函数，可以使用xavier_normal_\n",
    "                # 卷积后面有激活函数,用kaiming_normal_这个\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                # 因为这里没有bias,所以可以直接注释,对于有些有bias有些没有的地方,可以先判断再置0\n",
    "                # if m.bias!=None:\n",
    "                #     nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f8298c-f19b-47e4-8c9f-914bd2ec1f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==use ShuffleNetV2 mode 0.5==\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=ShuffleNetV2(scale=0.5)\n",
    "# print(net)\n",
    "data=torch.randn(4,3,224,224)\n",
    "out=net(data)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2997f51b-6b89-4ce9-9d91-9b36e44246b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShuffleNetV2(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (stage2): Sequential(\n",
       "    (0): ShuffleUnit(\n",
       "      (short): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU6(inplace=True)\n",
       "      )\n",
       "      (branch): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
       "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage3): Sequential(\n",
       "    (0): ShuffleUnit(\n",
       "      (short): Sequential(\n",
       "        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
       "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU6(inplace=True)\n",
       "      )\n",
       "      (branch): Sequential(\n",
       "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
       "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage4): Sequential(\n",
       "    (0): ShuffleUnit(\n",
       "      (short): Sequential(\n",
       "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU6(inplace=True)\n",
       "      )\n",
       "      (branch): Sequential(\n",
       "        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(192, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91fbd156-176a-45b4-b97a-3d859d175bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意torch里是宽高顺序,和PIL不同\n",
    "img_size=(224,224)\n",
    "# mean和std均值需要按照数据集来修改\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "batch=64\n",
    "lr=0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "269cec16-6c1f-457a-9b99-bf87a87e5200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare dataset and preprocessing\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.RandomCrop(img_size, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # 至少要加上下面这句ToTensor\n",
    "    transforms.ToTensor(),\n",
    "    # ciaf10固有均值标准差\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    # 至少要加上下面这句ToTensor\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09ebc819-7235-4291-bb65-bc36e0de6c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 23556\n",
      "val data 2623\n",
      "train label {'cane': 0, 'cavallo': 1, 'elefante': 2, 'farfalla': 3, 'gallina': 4, 'gatto': 5, 'mucca': 6, 'pecora': 7, 'ragno': 8, 'scoiattolo': 9}\n",
      "val label {'cane': 0, 'cavallo': 1, 'elefante': 2, 'farfalla': 3, 'gallina': 4, 'gatto': 5, 'mucca': 6, 'pecora': 7, 'ragno': 8, 'scoiattolo': 9}\n"
     ]
    }
   ],
   "source": [
    "# animals10数据集\n",
    "# 正常来说,train_set这个类是需要自己定义的,但是在官方数据集中已经给定义好了\n",
    "data_dir=\"D:/data/image/\"\n",
    "if not os.path.exists(data_dir):\n",
    "    # 尝试mac的文件夹\n",
    "    data_dir=\"~/data\"\n",
    "    if not os.path.exists(data_dir):\n",
    "            raise FileExistsError(\"data source not exist!\")\n",
    "train_set=datasets.ImageFolder(root=data_dir+'animals10/train',\n",
    "                        transform=transform_train)\n",
    "\n",
    "val_set=datasets.ImageFolder(root=data_dir+'animals10/val',\n",
    "                        transform=transform_val)\n",
    "train_set_len=len(train_set)\n",
    "val_set_len=len(val_set)\n",
    "print('train data',train_set_len)\n",
    "print('val data',val_set_len)\n",
    "print('train label',train_set.class_to_idx)\n",
    "print('val label',val_set.class_to_idx)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch,\n",
    "                                         shuffle=True, num_workers=6)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch,\n",
    "                                         shuffle=False, num_workers=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83715af8-ab1e-4cd7-a91f-0498e3b2808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcLoss(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super().__init__()\n",
    "        self.criterion=nn.CrossEntropyLoss()\n",
    "    def forward(self,y_true,y_pred):\n",
    "        return self.criterion(y_true,y_pred)\n",
    "    \n",
    "class TrainModel(object):\n",
    "    _defaults={\n",
    "        \"eopch\":2,\n",
    "    }\n",
    "    def __init__(self,net,loss,train_dataloder,optimizer,**kwargs):\n",
    "        '''\n",
    "        还支持传入字典参数\n",
    "        '''\n",
    "        self.__dict__.update(self._defaults)\n",
    "        self.net=net\n",
    "        self.loss=loss\n",
    "        self.dataloder=train_dataloder\n",
    "        self.optimizer=optimizer\n",
    "        for name, value in kwargs.items():\n",
    "            setattr(self, name, value)\n",
    "        self.device='cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "    def __call__(self,train_total_len,batch_size):\n",
    "        self.net.train()\n",
    "        # 需要注意这里写的是train_set的长度,如果写错成train_loader,返回的是数据集一共有多少个batch\n",
    "        with tqdm(total=train_total_len,desc=f'Train:') as pbar:\n",
    "            for idx,data in enumerate(self.dataloder):\n",
    "                data,label=data\n",
    "                data,label=data.to(self.device),label.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                # forward\n",
    "                outputs=self.net(data)\n",
    "                loss=self.loss(outputs,label)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                # 更新进度条\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "class TestModel(object):\n",
    "    _defaults={\n",
    "    \"eopch\":1,\n",
    "    }\n",
    "    def __init__(self,net,loss,val_dataloder,**kwargs):\n",
    "        '''\n",
    "        还支持传入字典参数\n",
    "        '''\n",
    "        self.__dict__.update(self._defaults)\n",
    "        self.net=net\n",
    "        self.loss=loss\n",
    "        self.dataloder=val_dataloder\n",
    "        for name, value in kwargs.items():\n",
    "            setattr(self, name, value)\n",
    "        self.device='cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "    def __call__(self,total_num,batch_size):\n",
    "        # eval 模式下,dropout失效,bn层参数采用之前训练的,不更新\n",
    "        self.net.eval()\n",
    "        val_loss=0\n",
    "        correct=0\n",
    "        with tqdm(total=total_num,desc=f'Validation:') as pbar:\n",
    "            # 不计算损失,这样速度更快\n",
    "            with torch.no_grad():\n",
    "                for idx,data in enumerate(self.dataloder):\n",
    "                    x,y=data\n",
    "                    x,y=x.to(self.device),y.to(self.device)\n",
    "                    y_pre=self.net(x)\n",
    "                    val_loss+=self.loss(y_pre,y).item()\n",
    "                    # max 第一个返回的是元素值,第二个为索引值\n",
    "                    # 求第一个维度的max,因此结果返回的是batch维度的max\n",
    "                    # 返回是一个第一个元素为值,第二个元素为idx的tuple\n",
    "                    pred=torch.max(y_pre,dim=1)[1]\n",
    "\n",
    "                    # pred维度为batch,每个元素为索引\n",
    "                    correct+=pred.eq(y).sum().item()\n",
    "                    # 更新进度条\n",
    "                    pbar.update(batch_size)\n",
    "            # 格式化打印直接有% 带f%这种{:.2f%}是错的格式,format这种有点坑\n",
    "            print(\"test loss {},accuracy {:.2%}\".format(val_loss,correct/total_num))\n",
    "        # 返回损失和准确率\n",
    "        return (val_loss,correct/total_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8236039-1e82-4b4f-af06-ce4964aedd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD(net.parameters(),lr=lr,momentum=0.9)\n",
    "loss=CalcLoss().to(device)\n",
    "train=TrainModel(net,loss,train_loader,optimizer)\n",
    "test=TestModel(net,loss,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e50119-ab06-4e9d-9e24-862098632fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train::  38%|██████████████████████████████                                                 | 8960/23556 [00:13<00:09, 1584.50it/s]"
     ]
    }
   ],
   "source": [
    "total_epoch=2\n",
    "for i in range(total_epoch):\n",
    "    train(train_set_len,batch)\n",
    "    test(val_set_len,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abde658-0961-4a34-8230-2a8b5722aba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
